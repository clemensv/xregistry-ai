{
  "id": "92c66a82-172a-45e6-92a4-ee6a053e95e6",
  "name": "io.github.66julienmartin/mcp-server-qwen_max",
  "description": "MCP server for Qwen Max model",
  "repository": {
    "url": "https://github.com/66julienmartin/MCP-server-Qwen_Max",
    "source": "github",
    "id": "927217229"
  },
  "version_detail": {
    "version": "0.0.1-seed",
    "release_date": "2025-05-16T19:13:07Z",
    "is_latest": true
  },
  "packages": [
    {
      "registry_name": "unknown",
      "name": "qwen_max",
      "version": "1.0.0",
      "environment_variables": [
        {
          "description": "your-api-key-here",
          "name": "DASHSCOPE_API_KEY"
        }
      ]
    }
  ],
  "tools": [
    {
      "name": "qwen_max",
      "description": "Generate text using Qwen Max model",
      "inputschema": {
        "type": "object",
        "properties": {
          "prompt": {
            "type": "string",
            "description": "The text prompt to generate content from"
          },
          "max_tokens": {
            "type": "number",
            "description": "Maximum number of tokens to generate",
            "default": 8192
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature (0-2)",
            "default": 0.7,
            "minimum": 0,
            "maximum": 2
          }
        },
        "required": [
          "prompt"
        ]
      }
    }
  ],
  "resources": [],
  "prompts": []
}